{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9cbcaf2",
   "metadata": {},
   "source": [
    "# BASELINE IMPUTATION OF MISSING VALUES\n",
    "\n",
    "## Description of this notebook\n",
    "\n",
    "This notebook imputes the missing data using univariate and multivariate techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c9c0536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all the necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "import miceforest as mf\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ebe878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir('..') # move to the general directory if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e97d68a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the incomplete dataset\n",
    "data_incomplete = pd.read_csv('DATA/data.csv')\n",
    "\n",
    "# Load the complete observed data to evaluate the performance\n",
    "data_observed = pd.read_csv('DATA/input_DATA_NO_NAs_INPUT.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a3ef99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the group of features\n",
    "subject_details = ['AGE', 'PTGENDER', 'PTEDUCAT', 'APOE4']\n",
    "fdg_pet = ['AngularLeft', 'AngularRight', 'CingulumPostBilateral', 'TemporalLeft', 'TemporalRight']\n",
    "nepb = ['MMSE', 'RAVLT_learning', 'RAVLT_immediate', 'RAVLT_perc_forgetting', 'FAQ']\n",
    "av_45 = ['CEREBELLUMGREYMATTER_UCBERKELEYAV45_10_17_16', 'WHOLECEREBELLUM_UCBERKELEYAV45_10_17_16', 'ERODED_SUBCORTICALWM_UCBERKELEYAV45_10_17_16', 'FRONTAL_UCBERKELEYAV45_10_17_16', \n",
    "               'CINGULATE_UCBERKELEYAV45_10_17_16', 'PARIETAL_UCBERKELEYAV45_10_17_16', 'TEMPORAL_UCBERKELEYAV45_10_17_16']\n",
    "csf_values = ['ABETA_UPENNBIOMK9_04_19_17', 'TAU_UPENNBIOMK9_04_19_17', 'PTAU_UPENNBIOMK9_04_19_17']\n",
    "mri = ['Hippocampus', 'WholeBrain', 'Ventricles', 'Entorhinal', 'Fusiform', 'MidTemp', 'ICV']\n",
    "\n",
    "groups = [subject_details, fdg_pet, nepb, av_45, csf_values, mri]\n",
    "group_names = ['subject_details', 'fdg_pet', 'nepb', 'av_45', 'csf_values', 'mri']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61f691d",
   "metadata": {},
   "source": [
    "## **1.** Univariate Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db852b1d",
   "metadata": {},
   "source": [
    "### **Overall Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a052d0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function evaluates the overall imputation performance of the univariate models using cros-validation\n",
    "def baseline_univariate_imputation_cv_performance(data, method_name, n_splits=10):\n",
    "   \n",
    "    r2_scores = []\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train_data = data.iloc[train_index].copy()\n",
    "        test_data = data.iloc[test_index].copy()\n",
    "\n",
    "        # Identify observed (not missing) values in the test set\n",
    "        observed_mask = test_data.notnull().values\n",
    "        observed_indices = np.where(observed_mask.flatten())[0]\n",
    "\n",
    "        # Randomly select 20% of these observed positions to insert synthetic NAs\n",
    "        n_mask = int(0.2 * len(observed_indices))\n",
    "        mask_indices = np.random.choice(observed_indices, size=n_mask, replace=False)\n",
    "\n",
    "        # Save the true values before masking for later comparison\n",
    "        test_data_flat = test_data.values.flatten()\n",
    "        true_values = test_data_flat[mask_indices].copy()\n",
    "\n",
    "        # Mask the defined positions\n",
    "        test_data_flat[mask_indices] = np.nan\n",
    "        test_data_masked = test_data_flat.reshape(test_data.shape)\n",
    "        test_data_masked_df = pd.DataFrame(test_data_masked, columns=test_data.columns, index=test_data.index)\n",
    "\n",
    "        # Fit the imputer using the training data\n",
    "        mean_imputer = SimpleImputer(strategy=method_name)\n",
    "        mean_imputer.fit(train_data)\n",
    "\n",
    "        # Impute the masked test data using the imputer fitted on training data\n",
    "        imputed_array = mean_imputer.transform(test_data_masked_df)\n",
    "        imputed_flat = imputed_array.flatten()\n",
    "\n",
    "        # Save the imputed values for later comparison\n",
    "        imputed_values = imputed_flat[mask_indices]\n",
    "\n",
    "        # Compute r2 score for each fold\n",
    "        score = r2_score(true_values, imputed_values)\n",
    "        r2_scores.append(score)\n",
    "\n",
    "    # Summarize the results computing the mean and standard deviation of the R2 scores across all 10 folds\n",
    "    avg_r2 = np.mean(r2_scores)\n",
    "    std_r2 = np.std(r2_scores)\n",
    "    return (f\"R² Score ({method_name} with CV): {avg_r2:.3f} ± {std_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b14983e",
   "metadata": {},
   "source": [
    "### **Subset Performance** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20476bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function evaluates the imputation performance in each subset of the univariate models using cros-validation\n",
    "def baseline_imputation_groups_cv(data, method_name, groups, group_names, n_splits=10):\n",
    "\n",
    "    group_r2_scores = {name: [] for name in group_names}\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_idx, test_idx in kf.split(data):\n",
    "        train_data = data.iloc[train_idx].copy()\n",
    "        test_data = data.iloc[test_idx].copy()\n",
    "\n",
    "        # Fit the corresponding imputer using the training data\n",
    "        imputer = SimpleImputer(strategy=method_name)\n",
    "        imputer.fit(train_data)\n",
    "\n",
    "        # Predict the masked data for each group\n",
    "        for group, name in zip(groups, group_names):\n",
    "            test_data_copy = test_data.copy()  \n",
    "\n",
    "            # Identify the observed (non-missing) positions in the group columns\n",
    "            observed_mask = test_data_copy[group].notnull().values\n",
    "            observed_positions = np.where(observed_mask.flatten())[0]\n",
    "\n",
    "            # Randomly select 20% of observed values to impute synthetic NAs\n",
    "            n_mask = int(len(observed_positions) * 0.2)\n",
    "            mask_indices = np.random.choice(observed_positions, size=n_mask, replace=False)\n",
    "\n",
    "            # Save true values before masking\n",
    "            group_values_flat = test_data_copy[group].values.flatten()\n",
    "            true_values = group_values_flat[mask_indices].copy()\n",
    "\n",
    "            # Mask the values in the full test_data_copy\n",
    "            group_values_flat[mask_indices] = np.nan\n",
    "            test_data_copy[group] = pd.DataFrame(group_values_flat.reshape(test_data_copy[group].shape), columns=group, \n",
    "                                                index=test_data_copy.index)\n",
    "\n",
    "            # Impute the masked positions\n",
    "            imputed_test_array = imputer.transform(test_data_copy)\n",
    "            imputed_test_df = pd.DataFrame(imputed_test_array, columns=test_data.columns, index=test_data.index)\n",
    "\n",
    "            # Store the imputed values \n",
    "            imputed_group_flat = imputed_test_df[group].values.flatten()\n",
    "            imputed_values = imputed_group_flat[mask_indices]\n",
    "\n",
    "            # Compute the r2 score\n",
    "            r2 = r2_score(true_values, imputed_values)\n",
    "            group_r2_scores[name].append(r2)\n",
    "\n",
    "    # Summarize the results by computing mean and standard deviation throughout all the folds\n",
    "    for name in group_names:\n",
    "        avg_r2 = np.mean(group_r2_scores[name])\n",
    "        std_r2 = np.std(group_r2_scores[name])\n",
    "        print(f\"R² ({name}): {avg_r2:.3f} ± {std_r2:.3f}\")\n",
    "        print('---------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bd5c72",
   "metadata": {},
   "source": [
    "### **1.1 Mean Imputation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577d9d35",
   "metadata": {},
   "source": [
    "#### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "178ec91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'R² Score (mean with CV): 0.988 ± 0.002'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_univariate_imputation_cv_performance(data_incomplete, 'mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d56ed062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² (subject_details): 0.984 ± 0.003\n",
      "---------------------------------------------\n",
      "R² (fdg_pet): 0.040 ± 0.034\n",
      "---------------------------------------------\n",
      "R² (nepb): 0.591 ± 0.088\n",
      "---------------------------------------------\n",
      "R² (av_45): 0.582 ± 0.048\n",
      "---------------------------------------------\n",
      "R² (csf_values): 0.604 ± 0.047\n",
      "---------------------------------------------\n",
      "R² (mri): 0.982 ± 0.003\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "baseline_imputation_groups_cv(data_incomplete, 'mean', groups, group_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b53ec7f",
   "metadata": {},
   "source": [
    "#### Create Imputed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7bfbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the missing entries in the incomplete data\n",
    "\n",
    "mean_imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "mean_imputed_data = mean_imputer.fit_transform(data_incomplete)\n",
    "\n",
    "mean_imputed_df = pd.DataFrame(mean_imputed_data, columns=data_incomplete.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1c0632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_imputed_df.to_csv('BASELINE IMPUTED DATASETS/mean_imputed_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef278edd",
   "metadata": {},
   "source": [
    "### **1.2 Median Imputation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a810445b",
   "metadata": {},
   "source": [
    "#### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c900dc6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'R² Score (median with CV): 0.987 ± 0.003'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_univariate_imputation_cv_performance(data_incomplete, 'median')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3aca6256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² (subject_details): 0.981 ± 0.003\n",
      "---------------------------------------------\n",
      "R² (fdg_pet): 0.025 ± 0.068\n",
      "---------------------------------------------\n",
      "R² (nepb): 0.586 ± 0.118\n",
      "---------------------------------------------\n",
      "R² (av_45): 0.574 ± 0.066\n",
      "---------------------------------------------\n",
      "R² (csf_values): 0.559 ± 0.040\n",
      "---------------------------------------------\n",
      "R² (mri): 0.983 ± 0.004\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "baseline_imputation_groups_cv(data_incomplete, 'median', groups, group_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abed291",
   "metadata": {},
   "source": [
    "#### Create Imputed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26e9126",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the missing entries in the incomplete data\n",
    "\n",
    "median_imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "median_imputed_data = median_imputer.fit_transform(data_incomplete)\n",
    "\n",
    "median_imputed_df = pd.DataFrame(median_imputed_data, columns=data_incomplete.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa3e1979",
   "metadata": {},
   "outputs": [],
   "source": [
    "median_imputed_df.to_csv('BASELINE IMPUTED DATASETS/median_imputed_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6db4133",
   "metadata": {},
   "source": [
    "### **1.3 Mode Imputation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0f76c6",
   "metadata": {},
   "source": [
    "#### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5bd2cc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'R² Score (most_frequent with CV): 0.974 ± 0.006'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_univariate_imputation_cv_performance(data_incomplete, 'most_frequent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d57e04e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² (subject_details): 0.982 ± 0.003\n",
      "---------------------------------------------\n",
      "R² (fdg_pet): -0.730 ± 0.287\n",
      "---------------------------------------------\n",
      "R² (nepb): 0.019 ± 0.294\n",
      "---------------------------------------------\n",
      "R² (av_45): -0.075 ± 0.282\n",
      "---------------------------------------------\n",
      "R² (csf_values): 0.510 ± 0.074\n",
      "---------------------------------------------\n",
      "R² (mri): 0.968 ± 0.005\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "baseline_imputation_groups_cv(data_incomplete, 'most_frequent', groups, group_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8dc582",
   "metadata": {},
   "source": [
    "#### Create Imputed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4232f626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the missing entries in the incomplete data\n",
    "\n",
    "mode_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "\n",
    "mode_imputed_data = mode_imputer.fit_transform(data_incomplete)\n",
    "\n",
    "mode_imputed_df = pd.DataFrame(mode_imputed_data, columns=data_incomplete.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e55a4be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_imputed_df.to_csv('BASELINE IMPUTED DATASETS/mode_imputed_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5baeef",
   "metadata": {},
   "source": [
    "## **2.** Multivariate Imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615c87d0",
   "metadata": {},
   "source": [
    "### **2.1 KNN Imputation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d537cb",
   "metadata": {},
   "source": [
    "#### **Overall Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4abc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function evaluates the overall imputation performance of KNN using cros-validation\n",
    "\n",
    "def knn_univariate_imputation_cv_performance(data, method_name, n_neighbors=3, n_splits=10):\n",
    "    \n",
    "    r2_scores = []\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train_data = data.iloc[train_index].copy()\n",
    "        test_data = data.iloc[test_index].copy()\n",
    "\n",
    "        # Identify observed values in the test set\n",
    "        observed_mask = test_data.notnull().values\n",
    "        observed_indices = np.where(observed_mask.flatten())[0]\n",
    "\n",
    "        # Randomly select 20% of these observed positions to impute synthetic NAs\n",
    "        n_mask = int(0.2 * len(observed_indices))\n",
    "        mask_indices = np.random.choice(observed_indices, size=n_mask, replace=False)\n",
    "\n",
    "        # Save the true values \n",
    "        test_data_flat = test_data.values.flatten()\n",
    "        true_values = test_data_flat[mask_indices].copy()\n",
    "\n",
    "        # Impute the synthetic NAs\n",
    "        test_data_flat[mask_indices] = np.nan\n",
    "        test_data_masked = test_data_flat.reshape(test_data.shape)\n",
    "        test_data_masked_df = pd.DataFrame(test_data_masked, columns=test_data.columns, index=test_data.index)\n",
    "\n",
    "        # Fit imputer on the training data \n",
    "        mean_imputer = KNNImputer(n_neighbors=n_neighbors)\n",
    "        mean_imputer.fit(train_data)\n",
    "\n",
    "        # Impute the masked test data \n",
    "        imputed_array = mean_imputer.transform(test_data_masked_df)\n",
    "        imputed_flat = imputed_array.flatten()\n",
    "\n",
    "        # Extract imputed values \n",
    "        imputed_values = imputed_flat[mask_indices]\n",
    "\n",
    "        # Compute the r2 score\n",
    "        score = r2_score(true_values, imputed_values)\n",
    "        r2_scores.append(score)\n",
    "\n",
    "    # Summarize results obtaining the mean and standard deviation across all the folds\n",
    "    avg_r2 = np.mean(r2_scores)\n",
    "    std_r2 = np.std(r2_scores)\n",
    "    return (f\"R² Score ({method_name} with CV): {avg_r2:.3f} ± {std_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d149f5e7",
   "metadata": {},
   "source": [
    "#### **Subset Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c9e437",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function evaluates the imputation performance in each subset of KNN using cros-validation\n",
    "def knn_imputation_groups_cv(data, groups, group_names, n_splits=10):\n",
    "\n",
    "    group_r2_scores = {name: [] for name in group_names}\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_idx, test_idx in kf.split(data):\n",
    "        train_data = data.iloc[train_idx].copy()\n",
    "        test_data = data.iloc[test_idx].copy()\n",
    "\n",
    "        # Fit the imputer using the training data\n",
    "        imputer = KNNImputer(n_neighbors=3)\n",
    "        imputer.fit(train_data)\n",
    "\n",
    "        # Impute the masked values in the test set for each group\n",
    "        for group, name in zip(groups, group_names):\n",
    "            test_data_copy = test_data.copy()  \n",
    "\n",
    "            # Identify observed positions in the group columns\n",
    "            observed_mask = test_data_copy[group].notnull().values\n",
    "            observed_positions = np.where(observed_mask.flatten())[0]\n",
    "\n",
    "            # Randomly select 20% of observed values to mask\n",
    "            n_mask = int(len(observed_positions) * 0.2)\n",
    "            mask_indices = np.random.choice(observed_positions, size=n_mask, replace=False)\n",
    "\n",
    "            # Save true values \n",
    "            group_values_flat = test_data_copy[group].values.flatten()\n",
    "            true_values = group_values_flat[mask_indices].copy()\n",
    "\n",
    "            # Mask the values in the test data\n",
    "            group_values_flat[mask_indices] = np.nan\n",
    "            test_data_copy[group] = pd.DataFrame(group_values_flat.reshape(test_data_copy[group].shape), columns=group, \n",
    "                                                index=test_data_copy.index)\n",
    "\n",
    "            # Impute the masked values\n",
    "            imputed_test_array = imputer.transform(test_data_copy)\n",
    "            imputed_test_df = pd.DataFrame(imputed_test_array, columns=test_data.columns, index=test_data.index)\n",
    "\n",
    "            # Store the imputed values \n",
    "            imputed_group_flat = imputed_test_df[group].values.flatten()\n",
    "            imputed_values = imputed_group_flat[mask_indices]\n",
    "\n",
    "            # Compute the r2 score \n",
    "            r2 = r2_score(true_values, imputed_values)\n",
    "            group_r2_scores[name].append(r2)\n",
    "\n",
    "    # Summarize the results computing the mean and standard deviation across all the folds\n",
    "    for name in group_names:\n",
    "        avg_r2 = np.mean(group_r2_scores[name])\n",
    "        std_r2 = np.std(group_r2_scores[name])\n",
    "        print(f\"R² ({name}): {avg_r2:.3f} ± {std_r2:.3f}\")\n",
    "        print('---------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ddd052b",
   "metadata": {},
   "source": [
    "#### **Step 1:** Decide which is the best number of nearest neighbors\n",
    "\n",
    "For a tradeoff between simplicity of the model and good performance, the number of nearest neighbors chosen to perform the imputation is 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "05d24481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors=2\n",
      "R² Score (KNN with CV): 0.979 ± 0.005\n",
      "n_neighbors=3\n",
      "R² Score (KNN with CV): 0.981 ± 0.003\n",
      "n_neighbors=4\n",
      "R² Score (KNN with CV): 0.979 ± 0.005\n",
      "n_neighbors=5\n",
      "R² Score (KNN with CV): 0.982 ± 0.004\n",
      "n_neighbors=6\n",
      "R² Score (KNN with CV): 0.983 ± 0.004\n",
      "n_neighbors=7\n",
      "R² Score (KNN with CV): 0.984 ± 0.003\n",
      "n_neighbors=8\n",
      "R² Score (KNN with CV): 0.985 ± 0.004\n",
      "n_neighbors=9\n",
      "R² Score (KNN with CV): 0.984 ± 0.002\n",
      "n_neighbors=10\n",
      "R² Score (KNN with CV): 0.985 ± 0.002\n"
     ]
    }
   ],
   "source": [
    "for n in range(2, 11):\n",
    "    print(f'n_neighbors={n}')\n",
    "    print(knn_univariate_imputation_cv_performance(data_incomplete, 'KNN', n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91479836",
   "metadata": {},
   "source": [
    "#### **Step 2:** Impute the missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5323420e",
   "metadata": {},
   "source": [
    "##### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "816eb97b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'R² Score (KNN with CV): 0.980 ± 0.005'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_univariate_imputation_cv_performance(data_incomplete, 'KNN', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f3a20a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² (subject_details): 0.981 ± 0.004\n",
      "---------------------------------------------\n",
      "R² (fdg_pet): -0.230 ± 0.189\n",
      "---------------------------------------------\n",
      "R² (nepb): 0.557 ± 0.036\n",
      "---------------------------------------------\n",
      "R² (av_45): 0.593 ± 0.059\n",
      "---------------------------------------------\n",
      "R² (csf_values): 0.465 ± 0.128\n",
      "---------------------------------------------\n",
      "R² (mri): 0.974 ± 0.006\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "knn_imputation_groups_cv(data_incomplete, groups, group_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993364cc",
   "metadata": {},
   "source": [
    "##### Create Imputed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14323ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the missing entries in the incomplete data\n",
    "\n",
    "knn_imputer = KNNImputer(n_neighbors=3)  \n",
    "\n",
    "knn_imputed_data = knn_imputer.fit_transform(data_incomplete)\n",
    "\n",
    "knn_imputed_df = pd.DataFrame(knn_imputed_data, columns=data_incomplete.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e3df62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_imputed_df.to_csv('BASELINE IMPUTED DATASETS/knn_imputed_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ab60fd",
   "metadata": {},
   "source": [
    "### **2.2 Iterative Imputation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b6ca58",
   "metadata": {},
   "source": [
    "#### **Overall Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f4ae9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function evaluates the overall imputation performance of Iterative using cros-validation\n",
    "\n",
    "def iter_univariate_imputation_cv_performance(data, method_name, n_splits=10):\n",
    "\n",
    "    r2_scores = []\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train_data = data.iloc[train_index].copy()\n",
    "        test_data = data.iloc[test_index].copy()\n",
    "\n",
    "        # Identify observed values in the test set\n",
    "        observed_mask = test_data.notnull().values\n",
    "        observed_indices = np.where(observed_mask.flatten())[0]\n",
    "\n",
    "        # Randomly select 20% of these observed positions to mask \n",
    "        n_mask = int(0.2 * len(observed_indices))\n",
    "        mask_indices = np.random.choice(observed_indices, size=n_mask, replace=False)\n",
    "\n",
    "        # Save the true values \n",
    "        test_data_flat = test_data.values.flatten()\n",
    "        true_values = test_data_flat[mask_indices].copy()\n",
    "\n",
    "        # Mask the positions\n",
    "        test_data_flat[mask_indices] = np.nan\n",
    "        test_data_masked = test_data_flat.reshape(test_data.shape)\n",
    "        test_data_masked_df = pd.DataFrame(test_data_masked, columns=test_data.columns, index=test_data.index)\n",
    "\n",
    "        # Fit imputer on training data \n",
    "        mean_imputer = IterativeImputer(estimator=LinearRegression(), max_iter=50, random_state=42)\n",
    "        mean_imputer.fit(train_data)\n",
    "\n",
    "        # Impute the masked test data using the imputer fitted on training data\n",
    "        imputed_array = mean_imputer.transform(test_data_masked_df)\n",
    "        imputed_flat = imputed_array.flatten()\n",
    "\n",
    "        # Store the imputed values \n",
    "        imputed_values = imputed_flat[mask_indices]\n",
    "\n",
    "        # Compute r2 score\n",
    "        score = r2_score(true_values, imputed_values)\n",
    "        r2_scores.append(score)\n",
    "\n",
    "    # Summarize results by computing the mean and standard deviation across all the folds\n",
    "    avg_r2 = np.mean(r2_scores)\n",
    "    std_r2 = np.std(r2_scores)\n",
    "    return (f\"R² Score ({method_name} with CV): {avg_r2:.3f} ± {std_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee4c3ebb",
   "metadata": {},
   "source": [
    "#### **Subset Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2abb7625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function evaluates the imputation performance in each subset of Iterative using cros-validation\n",
    "\n",
    "def iter_imputation_groups_cv(data, groups, group_names, n_splits=10):\n",
    "\n",
    "    group_r2_scores = {name: [] for name in group_names}\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_idx, test_idx in kf.split(data):\n",
    "        train_data = data.iloc[train_idx].copy()\n",
    "        test_data = data.iloc[test_idx].copy()\n",
    "\n",
    "        # Fit the imputer on the training data\n",
    "        imputer = IterativeImputer(estimator=LinearRegression(), max_iter=50, random_state=42)\n",
    "        imputer.fit(train_data)\n",
    "\n",
    "        # Predict the mask positions in each group\n",
    "        for group, name in zip(groups, group_names):\n",
    "            test_data_copy = test_data.copy()  \n",
    "\n",
    "            # Identify observed positions in the group columns\n",
    "            observed_mask = test_data_copy[group].notnull().values\n",
    "            observed_positions = np.where(observed_mask.flatten())[0]\n",
    "\n",
    "            # Randomly select 20% of observed values to mask\n",
    "            n_mask = int(len(observed_positions) * 0.2)\n",
    "            mask_indices = np.random.choice(observed_positions, size=n_mask, replace=False)\n",
    "\n",
    "            # Save true values \n",
    "            group_values_flat = test_data_copy[group].values.flatten()\n",
    "            true_values = group_values_flat[mask_indices].copy()\n",
    "\n",
    "            # Mask the values\n",
    "            group_values_flat[mask_indices] = np.nan\n",
    "            test_data_copy[group] = pd.DataFrame(group_values_flat.reshape(test_data_copy[group].shape), \n",
    "                                                columns=group, \n",
    "                                                index=test_data_copy.index)\n",
    "\n",
    "            # Impute the masked values\n",
    "            imputed_test_array = imputer.transform(test_data_copy)\n",
    "            imputed_test_df = pd.DataFrame(imputed_test_array, columns=test_data.columns, index=test_data.index)\n",
    "\n",
    "            # Store the imputed values \n",
    "            imputed_group_flat = imputed_test_df[group].values.flatten()\n",
    "            imputed_values = imputed_group_flat[mask_indices]\n",
    "\n",
    "            # Compute the r2 score\n",
    "            r2 = r2_score(true_values, imputed_values)\n",
    "            group_r2_scores[name].append(r2)\n",
    "\n",
    "    # Summarize the results by computing the mean and standard deviation of the scores across all the folds\n",
    "    for name in group_names:\n",
    "        avg_r2 = np.mean(group_r2_scores[name])\n",
    "        std_r2 = np.std(group_r2_scores[name])\n",
    "        print(f\"R² ({name}): {avg_r2:.3f} ± {std_r2:.3f}\")\n",
    "        print('---------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4875f1",
   "metadata": {},
   "source": [
    "#### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "278c8baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'R² Score (Iterative with CV): 0.997 ± 0.001'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iter_univariate_imputation_cv_performance(data_incomplete, 'Iterative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "753dbc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² (subject_details): 0.988 ± 0.001\n",
      "---------------------------------------------\n",
      "R² (fdg_pet): 0.763 ± 0.050\n",
      "---------------------------------------------\n",
      "R² (nepb): 0.823 ± 0.072\n",
      "---------------------------------------------\n",
      "R² (av_45): 0.966 ± 0.008\n",
      "---------------------------------------------\n",
      "R² (csf_values): 0.787 ± 0.072\n",
      "---------------------------------------------\n",
      "R² (mri): 0.996 ± 0.001\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "iter_imputation_groups_cv(data_incomplete, groups, group_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c874be",
   "metadata": {},
   "source": [
    "#### Create Imputed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e77eac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the missing entries in the incomplete data\n",
    "\n",
    "iter_imputer = IterativeImputer(estimator=LinearRegression(), max_iter=50, random_state=42)\n",
    "\n",
    "iterative_imputer_data = iter_imputer.fit_transform(data_incomplete)\n",
    "\n",
    "iter_imputed_df = pd.DataFrame(iterative_imputer_data, columns=data_incomplete.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40b91384",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_imputed_df.to_csv('BASELINE IMPUTED DATASETS/iter_imputed_df.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da36f75",
   "metadata": {},
   "source": [
    "### **2.3 MICE Imputation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfecd18b",
   "metadata": {},
   "source": [
    "#### **Define the Imputer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28fc665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the class to perform MICE\n",
    "class MICE_Imputer:\n",
    "    def __init__(self, num_datasets=10, mice_iterations=5, random_state=42):\n",
    "        # number of imputed datasets to generate in each iteration\n",
    "        self.num_datasets = num_datasets \n",
    "        # number of iterations desired\n",
    "        self.mice_iterations = mice_iterations\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X):\n",
    "        # Create of kernel object and input data\n",
    "        self.kernel = mf.ImputationKernel(\n",
    "            X,\n",
    "            num_datasets=self.num_datasets,\n",
    "            random_state=self.random_state\n",
    "        )\n",
    "        # Run the MICE iteration \n",
    "        self.kernel.mice(self.mice_iterations)\n",
    "\n",
    "    def transform(self, X):\n",
    "        # Create a new kernel for imputing new values\n",
    "        new_kernel = mf.ImputationKernel(\n",
    "            X,\n",
    "            num_datasets=self.num_datasets,\n",
    "            random_state=self.random_state,\n",
    "        )\n",
    "        # Trigger initialization of the kernel\n",
    "        new_kernel.complete_data(dataset=0)  \n",
    "\n",
    "        # Use parameters from the firsr kernel to initialize the new kernel\n",
    "        new_kernel.models = self.kernel.models\n",
    "\n",
    "        # Run mice iterations on new data\n",
    "        new_kernel.mice(self.mice_iterations)\n",
    "\n",
    "        # Return completed dataset \n",
    "        completed_df = [self.kernel.complete_data(dataset=i) for i in range(self.num_datasets)]\n",
    "        df = sum(completed_df) / len(completed_df)\n",
    "        return df\n",
    "\n",
    "    def fit_transform(self, X):\n",
    "        # Fit the imputer\n",
    "        self.fit(X)\n",
    "\n",
    "        # Generate the multiple imputed datasets\n",
    "        imputed_dfs = [self.kernel.complete_data(dataset=i) for i in range(self.num_datasets)]\n",
    "\n",
    "        # Average the imputed datasets to general a final one\n",
    "        df = sum(imputed_dfs) / len(imputed_dfs)\n",
    "        \n",
    "        return pd.DataFrame(df, columns=X.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5377976a",
   "metadata": {},
   "source": [
    "#### **Overall Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e65f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function evaluates the overall imputation performance of MICE using cros-validation\n",
    "\n",
    "def mice_univariate_imputation_cv_performance(data, method_name, n_splits=10):\n",
    "    \n",
    "    r2_scores = []\n",
    "\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "    for train_index, test_index in kf.split(data):\n",
    "        train_data = data.iloc[train_index].copy().reset_index(drop=True)\n",
    "        test_data = data.iloc[test_index].copy().reset_index(drop=True)\n",
    "\n",
    "        # Identify observed values in the test set\n",
    "        observed_mask = test_data.notnull().values\n",
    "        observed_indices = np.where(observed_mask.flatten())[0]\n",
    "\n",
    "        # Randomly select 20% of these observed positions to mask \n",
    "        n_mask = int(0.2 * len(observed_indices))\n",
    "        mask_indices = np.random.choice(observed_indices, size=n_mask, replace=False)\n",
    "\n",
    "        # Save the true values\n",
    "        test_data_flat = test_data.values.flatten()\n",
    "        true_values = test_data_flat[mask_indices].copy()\n",
    "\n",
    "        # Mask those positions\n",
    "        test_data_flat[mask_indices] = np.nan\n",
    "        test_data_masked = test_data_flat.reshape(test_data.shape)\n",
    "        test_data_masked_df = pd.DataFrame(test_data_masked, columns=test_data.columns, index=test_data.index)\n",
    "\n",
    "        # Fit imputer on training data \n",
    "        mean_imputer = MICE_Imputer(num_datasets=10, mice_iterations=5)\n",
    "        mean_imputer.fit(train_data)\n",
    "\n",
    "        # Impute the masked test data using the imputer fitted on training data\n",
    "        imputed_array = mean_imputer.transform(test_data_masked_df)\n",
    "        imputed_array = np.array(imputed_array)\n",
    "        if isinstance(imputed_array, pd.DataFrame):\n",
    "            imputed_flat = imputed_array.values.flatten()\n",
    "        else:\n",
    "            imputed_flat = imputed_array.flatten()\n",
    "\n",
    "        # Store the imputed values \n",
    "        imputed_values = imputed_flat[mask_indices]\n",
    "\n",
    "        # Compute r2 score\n",
    "        score = r2_score(true_values, imputed_values)\n",
    "        r2_scores.append(score)\n",
    "\n",
    "    # Summarize results by computing the mean and standard deviation of the scores obtained in all the folds\n",
    "    avg_r2 = np.mean(r2_scores)\n",
    "    std_r2 = np.std(r2_scores)\n",
    "    return (f\"R² Score ({method_name} with CV): {avg_r2:.3f} ± {std_r2:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115b5495",
   "metadata": {},
   "source": [
    "#### **Subset Performance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c6b230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function evaluates the imputation performance in each subset of MICE using cros-validation\n",
    "\n",
    "def mice_imputation_groups_cv(data, groups, group_names, n_splits=10):\n",
    "\n",
    "    group_r2_scores = {name: [] for name in group_names}\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "    for train_idx, test_idx in kf.split(data):\n",
    "\n",
    "        train_data = data.iloc[train_idx].copy().reset_index(drop=True)\n",
    "        test_data = data.iloc[test_idx].copy().reset_index(drop=True)\n",
    "\n",
    "        # Fit the imputer using the training data\n",
    "        imputer = MICE_Imputer(num_datasets=10, mice_iterations=5)\n",
    "        imputer.fit(train_data)\n",
    "        \n",
    "        # Predict the masked test data in each group\n",
    "        for group, name in zip(groups, group_names):\n",
    "            test_data_copy = test_data.copy()  \n",
    "\n",
    "            # Identify observed positions in the group columns\n",
    "            observed_mask = test_data_copy[group].notnull().values\n",
    "            observed_positions = np.where(observed_mask.flatten())[0]\n",
    "\n",
    "            # Randomly select 20% of observed values to mask\n",
    "            n_mask = int(len(observed_positions) * 0.2)\n",
    "            mask_indices = np.random.choice(observed_positions, size=n_mask, replace=False)\n",
    "\n",
    "            # Save true values\n",
    "            group_values_flat = test_data_copy[group].values.flatten()\n",
    "            true_values = group_values_flat[mask_indices].copy()\n",
    "\n",
    "            # Mask values\n",
    "            group_values_flat[mask_indices] = np.nan\n",
    "            test_data_copy[group] = pd.DataFrame(group_values_flat.reshape(test_data_copy[group].shape), \n",
    "                                                columns=group, \n",
    "                                                index=test_data_copy.index)\n",
    "\n",
    "            # Impute the masked values\n",
    "            imputed_test_array = imputer.transform(test_data_copy)\n",
    "            imputed_test_df = pd.DataFrame(imputed_test_array, columns=test_data.columns, index=test_data.index)\n",
    "\n",
    "            # Store the imputed values\n",
    "            imputed_group_flat = imputed_test_df[group].values.flatten()\n",
    "            imputed_values = imputed_group_flat[mask_indices]\n",
    "\n",
    "            # Compute the r2 score\n",
    "            r2 = r2_score(true_values, imputed_values)\n",
    "            group_r2_scores[name].append(r2)\n",
    "\n",
    "    # Summarize the results calculating the mean and standard deviation of the scores across all the folds\n",
    "    for name in group_names:\n",
    "        avg_r2 = np.mean(group_r2_scores[name])\n",
    "        std_r2 = np.std(group_r2_scores[name])\n",
    "        print(f\"R² ({name}): {avg_r2:.3f} ± {std_r2:.3f}\")\n",
    "        print('---------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b1bac6",
   "metadata": {},
   "source": [
    "#### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f8735a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'R² Score (MICE with CV): 0.994 ± 0.001'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mice_univariate_imputation_cv_performance(data_incomplete, 'MICE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bde428f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² (subject_details): 0.983 ± 0.004\n",
      "---------------------------------------------\n",
      "R² (fdg_pet): 0.638 ± 0.079\n",
      "---------------------------------------------\n",
      "R² (nepb): 0.770 ± 0.063\n",
      "---------------------------------------------\n",
      "R² (av_45): 0.914 ± 0.038\n",
      "---------------------------------------------\n",
      "R² (csf_values): 0.660 ± 0.094\n",
      "---------------------------------------------\n",
      "R² (mri): 0.993 ± 0.001\n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "mice_imputation_groups_cv(data_incomplete, groups, group_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df613cf",
   "metadata": {},
   "source": [
    "#### Create Imputed Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1edaa2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute the missing entries in the incomplete data\n",
    "\n",
    "mice_imputer = MICE_Imputer(num_datasets=10, mice_iterations=5)\n",
    "\n",
    "mice_imputed_df = mice_imputer.fit_transform(data_incomplete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1d422880",
   "metadata": {},
   "outputs": [],
   "source": [
    "mice_imputed_df.to_csv('BASELINE IMPUTED DATASETS/mice_imputed_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
